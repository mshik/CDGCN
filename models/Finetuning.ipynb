{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/iit\n"
     ]
    }
   ],
   "source": [
    "%cd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1282,
     "status": "ok",
     "timestamp": 1613395455582,
     "user": {
      "displayName": "Shikha Mallick",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjoRyV4TB5l3kSyBeE28ldIN2S1glHF3FTZvVEf_Q=s64",
      "userId": "13917264246341255180"
     },
     "user_tz": -330
    },
    "id": "L15osP6jjS28",
    "outputId": "5ba6a7d3-69f9-44d1-904b-0c160b70c9ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\r\n",
      "Copyright (c) 2005-2021 NVIDIA Corporation\r\n",
      "Built on Sun_Feb_14_21:12:58_PST_2021\r\n",
      "Cuda compilation tools, release 11.2, V11.2.152\r\n",
      "Build cuda_11.2.r11.2/compiler.29618528_0\r\n"
     ]
    }
   ],
   "source": [
    "# Check cuda version\n",
    "!nvcc --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QA-E_qsef5-L"
   },
   "source": [
    "# Import RDKit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "executionInfo": {
     "elapsed": 155754,
     "status": "ok",
     "timestamp": 1613395613914,
     "user": {
      "displayName": "Shikha Mallick",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjoRyV4TB5l3kSyBeE28ldIN2S1glHF3FTZvVEf_Q=s64",
      "userId": "13917264246341255180"
     },
     "user_tz": -330
    },
    "id": "aSRopUnCRdvD"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('/usr/local/lib/python3.7/site-packages/')\n",
    "\n",
    "try:\n",
    "    import rdkit\n",
    "    from rdkit import Chem\n",
    "    from rdkit.Chem import Draw\n",
    "    from rdkit.Chem import rdmolfiles\n",
    "    from rdkit.Chem.Draw import IPythonConsole\n",
    "    IPythonConsole.ipython_useSVG=True\n",
    "except ImportError:\n",
    "    print('Stopping RUNTIME. Colaboratory will restart automatically. Please run again.')\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 167
    },
    "executionInfo": {
     "elapsed": 154612,
     "status": "ok",
     "timestamp": 1613395613917,
     "user": {
      "displayName": "Shikha Mallick",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjoRyV4TB5l3kSyBeE28ldIN2S1glHF3FTZvVEf_Q=s64",
      "userId": "13917264246341255180"
     },
     "user_tz": -330
    },
    "id": "DsV4EWH_9ZmF",
    "outputId": "0355e97c-99cd-41e9-b6df-d23034bac70f"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "image/svg+xml": [
       "<?xml version='1.0' encoding='iso-8859-1'?>\n",
       "<svg version='1.1' baseProfile='full'\n",
       "              xmlns='http://www.w3.org/2000/svg'\n",
       "                      xmlns:rdkit='http://www.rdkit.org/xml'\n",
       "                      xmlns:xlink='http://www.w3.org/1999/xlink'\n",
       "                  xml:space='preserve'\n",
       "width='450px' height='150px' viewBox='0 0 450 150'>\n",
       "<!-- END OF HEADER -->\n",
       "<rect style='opacity:1.0;fill:#FFFFFF;stroke:none' width='450' height='150' x='0' y='0'> </rect>\n",
       "<path class='bond-0' d='M 68.2133,38.0896 L 75.6676,47.3812' style='fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1' />\n",
       "<path class='bond-0' d='M 75.6676,47.3812 L 83.1219,56.6727' style='fill:none;fill-rule:evenodd;stroke:#FF0000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1' />\n",
       "<path class='bond-1' d='M 112.087,57.3447 L 112.272,58.5455' style='fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:1.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1' />\n",
       "<path class='bond-1' d='M 106.932,57.5225 L 107.301,59.9242' style='fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:1.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1' />\n",
       "<path class='bond-1' d='M 101.777,57.7002 L 102.331,61.3028' style='fill:none;fill-rule:evenodd;stroke:#FF0000;stroke-width:1.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1' />\n",
       "<path class='bond-1' d='M 96.622,57.878 L 97.3604,62.6815' style='fill:none;fill-rule:evenodd;stroke:#FF0000;stroke-width:1.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1' />\n",
       "<path class='bond-1' d='M 91.4671,58.0558 L 92.39,64.0601' style='fill:none;fill-rule:evenodd;stroke:#FF0000;stroke-width:1.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1' />\n",
       "<path class='bond-2' d='M 117.242,57.1669 L 128.256,28.8602' style='fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1' />\n",
       "<path class='bond-27' d='M 117.242,57.1669 L 136.249,80.8589' style='fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1' />\n",
       "<path class='bond-3' d='M 128.256,28.8602 L 158.278,24.2455' style='fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1' />\n",
       "<path class='bond-4' d='M 177.285,47.9374 L 160.647,22.3447 L 155.909,26.1462 Z' style='fill:#000000;fill-rule:evenodd;fill-opacity:1;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1;' />\n",
       "<path class='bond-5' d='M 177.285,47.9374 L 166.271,76.2442' style='fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1' />\n",
       "<path class='bond-7' d='M 177.285,47.9374 L 191.198,20.9371' style='fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1' />\n",
       "<path class='bond-30' d='M 177.285,47.9374 L 198.664,69.5129' style='fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1' />\n",
       "<path class='bond-6' d='M 166.271,76.2442 L 136.249,80.8589' style='fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1' />\n",
       "<path class='bond-8' d='M 191.198,20.9371 L 221.176,25.8254' style='fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1' />\n",
       "<path class='bond-9' d='M 221.176,25.8254 L 225.791,55.8468' style='fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1' />\n",
       "<path class='bond-9' d='M 227.872,29.4057 L 231.103,50.4207' style='fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1' />\n",
       "<path class='bond-28' d='M 221.176,25.8254 L 244.868,6.81818' style='fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1' />\n",
       "<path class='bond-10' d='M 225.791,55.8468 L 198.664,69.5129' style='fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1' />\n",
       "<path class='bond-16' d='M 225.791,55.8468 L 254.097,66.8611' style='fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1' />\n",
       "<path class='bond-11' d='M 198.664,69.5129 L 196.182,66.4394 L 196.094,72.5136 Z' style='fill:#000000;fill-rule:evenodd;fill-opacity:1;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1;' />\n",
       "<path class='bond-31' d='M 198.664,69.5129 L 199.868,69.8969' style='fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1' />\n",
       "<path class='bond-31' d='M 199.868,69.8969 L 201.072,70.281' style='fill:none;fill-rule:evenodd;stroke:#0000FF;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1' />\n",
       "<path class='bond-12' d='M 196.138,69.4765 L 198.386,69.8954' style='fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1' />\n",
       "<path class='bond-12' d='M 198.386,69.8954 L 200.635,70.3142' style='fill:none;fill-rule:evenodd;stroke:#FF0000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1' />\n",
       "<path class='bond-13' d='M 200.54,70.3955 L 196.441,69.7272' style='fill:none;fill-rule:evenodd;stroke:#FF0000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1' />\n",
       "<path class='bond-13' d='M 196.441,69.7272 L 192.342,69.0588' style='fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1' />\n",
       "<path class='bond-14' d='M 192.342,69.0588 L 194.966,69.4261' style='fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1' />\n",
       "<path class='bond-14' d='M 194.966,69.4261 L 197.589,69.7935' style='fill:none;fill-rule:evenodd;stroke:#0000FF;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1' />\n",
       "<path class='bond-14' d='M 192.624,72.7787 L 194.46,73.0358' style='fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1' />\n",
       "<path class='bond-14' d='M 194.46,73.0358 L 196.297,73.2929' style='fill:none;fill-rule:evenodd;stroke:#0000FF;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1' />\n",
       "<path class='bond-15' d='M 192.342,69.0588 L 175.244,98.7235' style='fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1' />\n",
       "<path class='bond-15' d='M 175.244,98.7235 L 158.146,128.388' style='fill:none;fill-rule:evenodd;stroke:#0000FF;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1' />\n",
       "<path class='bond-17' d='M 254.097,66.8611 L 277.789,47.8539' style='fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1' />\n",
       "<path class='bond-17' d='M 253.85,59.2716 L 270.434,45.9666' style='fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1' />\n",
       "<path class='bond-18' d='M 277.789,47.8539 L 273.175,17.8324' style='fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1' />\n",
       "<path class='bond-20' d='M 277.789,47.8539 L 306.096,58.8682' style='fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1' />\n",
       "<path class='bond-19' d='M 273.175,17.8324 L 244.868,6.81818' style='fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1' />\n",
       "<path class='bond-19' d='M 266.726,21.8416 L 246.911,14.1317' style='fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1' />\n",
       "<path class='bond-21' d='M 306.096,58.8682 L 310.711,88.8896' style='fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1' />\n",
       "<path class='bond-21' d='M 312.792,62.4484 L 316.023,83.4635' style='fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1' />\n",
       "<path class='bond-29' d='M 306.096,58.8682 L 329.788,39.861' style='fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1' />\n",
       "<path class='bond-22' d='M 310.711,88.8896 L 322.853,93.6144' style='fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1' />\n",
       "<path class='bond-22' d='M 322.853,93.6144 L 334.996,98.3391' style='fill:none;fill-rule:evenodd;stroke:#0000FF;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1' />\n",
       "<path class='bond-23' d='M 343.039,96.6776 L 352.874,88.7871' style='fill:none;fill-rule:evenodd;stroke:#0000FF;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1' />\n",
       "<path class='bond-23' d='M 352.874,88.7871 L 362.709,80.8967' style='fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1' />\n",
       "<path class='bond-23' d='M 342.188,89.572 L 349.073,84.0487' style='fill:none;fill-rule:evenodd;stroke:#0000FF;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1' />\n",
       "<path class='bond-23' d='M 349.073,84.0487 L 355.957,78.5254' style='fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1' />\n",
       "<path class='bond-24' d='M 362.709,80.8967 L 358.095,50.8752' style='fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1' />\n",
       "<path class='bond-25' d='M 358.095,50.8752 L 329.788,39.861' style='fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1' />\n",
       "<path class='bond-25' d='M 351.646,54.8844 L 331.831,47.1744' style='fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1' />\n",
       "<path class='bond-26' d='M 358.095,50.8752 L 381.787,31.868' style='fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1' />\n",
       "<path  class='atom-1' d='M 83.2719 61.8059\n",
       "Q 83.2719 59.7405, 84.2925 58.5863\n",
       "Q 85.3131 57.4321, 87.2205 57.4321\n",
       "Q 89.128 57.4321, 90.1486 58.5863\n",
       "Q 91.1692 59.7405, 91.1692 61.8059\n",
       "Q 91.1692 63.8957, 90.1365 65.0863\n",
       "Q 89.1037 66.2648, 87.2205 66.2648\n",
       "Q 85.3252 66.2648, 84.2925 65.0863\n",
       "Q 83.2719 63.9078, 83.2719 61.8059\n",
       "M 87.2205 65.2929\n",
       "Q 88.5327 65.2929, 89.2374 64.4181\n",
       "Q 89.9542 63.5312, 89.9542 61.8059\n",
       "Q 89.9542 60.1171, 89.2374 59.2667\n",
       "Q 88.5327 58.404, 87.2205 58.404\n",
       "Q 85.9084 58.404, 85.1916 59.2545\n",
       "Q 84.4869 60.105, 84.4869 61.8059\n",
       "Q 84.4869 63.5433, 85.1916 64.4181\n",
       "Q 85.9084 65.2929, 87.2205 65.2929\n",
       "' fill='#FF0000'/>\n",
       "<path  class='atom-13' d='M 200.855 71.1152\n",
       "Q 200.855 69.0497, 201.876 67.8955\n",
       "Q 202.896 66.7413, 204.804 66.7413\n",
       "Q 206.711 66.7413, 207.732 67.8955\n",
       "Q 208.752 69.0497, 208.752 71.1152\n",
       "Q 208.752 73.2049, 207.72 74.3956\n",
       "Q 206.687 75.5741, 204.804 75.5741\n",
       "Q 202.908 75.5741, 201.876 74.3956\n",
       "Q 200.855 73.217, 200.855 71.1152\n",
       "M 204.804 74.6021\n",
       "Q 206.116 74.6021, 206.821 73.7273\n",
       "Q 207.537 72.8404, 207.537 71.1152\n",
       "Q 207.537 69.4264, 206.821 68.5759\n",
       "Q 206.116 67.7133, 204.804 67.7133\n",
       "Q 203.492 67.7133, 202.775 68.5637\n",
       "Q 202.07 69.4142, 202.07 71.1152\n",
       "Q 202.07 72.8526, 202.775 73.7273\n",
       "Q 203.492 74.6021, 204.804 74.6021\n",
       "' fill='#FF0000'/>\n",
       "<path  class='atom-15' d='M 199.17 65.9801\n",
       "L 201.989 70.5362\n",
       "Q 202.268 70.9857, 202.718 71.7998\n",
       "Q 203.168 72.6138, 203.192 72.6624\n",
       "L 203.192 65.9801\n",
       "L 204.334 65.9801\n",
       "L 204.334 74.582\n",
       "L 203.155 74.582\n",
       "L 200.13 69.6007\n",
       "Q 199.778 69.0175, 199.401 68.3493\n",
       "Q 199.037 67.681, 198.927 67.4745\n",
       "L 198.927 74.582\n",
       "L 197.81 74.582\n",
       "L 197.81 65.9801\n",
       "L 199.17 65.9801\n",
       "' fill='#0000FF'/>\n",
       "<path  class='atom-15' d='M 205.367 65.9801\n",
       "L 206.533 65.9801\n",
       "L 206.533 69.6371\n",
       "L 210.931 69.6371\n",
       "L 210.931 65.9801\n",
       "L 212.098 65.9801\n",
       "L 212.098 74.582\n",
       "L 210.931 74.582\n",
       "L 210.931 70.6091\n",
       "L 206.533 70.6091\n",
       "L 206.533 74.582\n",
       "L 205.367 74.582\n",
       "L 205.367 65.9801\n",
       "' fill='#0000FF'/>\n",
       "<path  class='atom-15' d='M 212.819 67.5306\n",
       "L 214.335 67.5306\n",
       "L 214.335 65.9349\n",
       "L 215.008 65.9349\n",
       "L 215.008 67.5306\n",
       "L 216.564 67.5306\n",
       "L 216.564 68.108\n",
       "L 215.008 68.108\n",
       "L 215.008 69.7117\n",
       "L 214.335 69.7117\n",
       "L 214.335 68.108\n",
       "L 212.819 68.108\n",
       "L 212.819 67.5306\n",
       "' fill='#0000FF'/>\n",
       "<path  class='atom-16' d='M 139.35 130.279\n",
       "L 140.517 130.279\n",
       "L 140.517 133.936\n",
       "L 144.915 133.936\n",
       "L 144.915 130.279\n",
       "L 146.081 130.279\n",
       "L 146.081 138.881\n",
       "L 144.915 138.881\n",
       "L 144.915 134.908\n",
       "L 140.517 134.908\n",
       "L 140.517 138.881\n",
       "L 139.35 138.881\n",
       "L 139.35 130.279\n",
       "' fill='#0000FF'/>\n",
       "<path  class='atom-16' d='M 146.498 138.579\n",
       "Q 146.707 138.042, 147.204 137.745\n",
       "Q 147.701 137.44, 148.391 137.44\n",
       "Q 149.249 137.44, 149.73 137.905\n",
       "Q 150.211 138.371, 150.211 139.196\n",
       "Q 150.211 140.038, 149.585 140.824\n",
       "Q 148.968 141.61, 147.685 142.54\n",
       "L 150.307 142.54\n",
       "L 150.307 143.182\n",
       "L 146.482 143.182\n",
       "L 146.482 142.645\n",
       "Q 147.541 141.891, 148.166 141.329\n",
       "Q 148.8 140.768, 149.104 140.263\n",
       "Q 149.409 139.758, 149.409 139.237\n",
       "Q 149.409 138.691, 149.136 138.387\n",
       "Q 148.864 138.082, 148.391 138.082\n",
       "Q 147.934 138.082, 147.629 138.266\n",
       "Q 147.324 138.451, 147.108 138.86\n",
       "L 146.498 138.579\n",
       "' fill='#0000FF'/>\n",
       "<path  class='atom-16' d='M 152.676 130.279\n",
       "L 155.495 134.835\n",
       "Q 155.774 135.285, 156.224 136.099\n",
       "Q 156.674 136.913, 156.698 136.961\n",
       "L 156.698 130.279\n",
       "L 157.84 130.279\n",
       "L 157.84 138.881\n",
       "L 156.661 138.881\n",
       "L 153.636 133.9\n",
       "Q 153.284 133.316, 152.907 132.648\n",
       "Q 152.543 131.98, 152.433 131.773\n",
       "L 152.433 138.881\n",
       "L 151.316 138.881\n",
       "L 151.316 130.279\n",
       "L 152.676 130.279\n",
       "' fill='#0000FF'/>\n",
       "<path  class='atom-23' d='M 337.116 95.6029\n",
       "L 339.935 100.159\n",
       "Q 340.214 100.609, 340.664 101.423\n",
       "Q 341.113 102.237, 341.138 102.285\n",
       "L 341.138 95.6029\n",
       "L 342.28 95.6029\n",
       "L 342.28 104.205\n",
       "L 341.101 104.205\n",
       "L 338.076 99.2235\n",
       "Q 337.723 98.6403, 337.347 97.9721\n",
       "Q 336.982 97.3039, 336.873 97.0973\n",
       "L 336.873 104.205\n",
       "L 335.755 104.205\n",
       "L 335.755 95.6029\n",
       "L 337.116 95.6029\n",
       "' fill='#0000FF'/>\n",
       "<path d='M 196.64,71.5378 L 196.64,67.4879 L 200.689,67.4879 L 200.689,71.5378 L 196.64,71.5378' style='fill:none;stroke:#FF0000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1;' />\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<rdkit.Chem.rdchem.Mol at 0x7f6c5ece1cb0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mol = Chem.MolFromSmiles('CO[C@@H]1CC[C@@]2(CC1)Cc1c([C@]32COC(=[NH+]3)N)cc(cc1)c1cncc(c1)C')\n",
    "mol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5ZXs3kkbgLFc"
   },
   "source": [
    "# Import required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "executionInfo": {
     "elapsed": 3978,
     "status": "ok",
     "timestamp": 1613396078946,
     "user": {
      "displayName": "Shikha Mallick",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjoRyV4TB5l3kSyBeE28ldIN2S1glHF3FTZvVEf_Q=s64",
      "userId": "13917264246341255180"
     },
     "user_tz": -330
    },
    "id": "c1oWZq_59bg8"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import sys\n",
    "import time\n",
    "import json\n",
    "import math\n",
    "import random\n",
    "import argparse\n",
    "import itertools\n",
    "import numpy as np\n",
    "import mxnet as mx\n",
    "import networkx as nx\n",
    "from scipy import sparse\n",
    "from mxnet.gluon import nn\n",
    "from mxnet.autograd import Function\n",
    "from mxnet.gluon.data import Dataset\n",
    "from mxnet import gluon, autograd, nd\n",
    "from mxnet.gluon.data import DataLoader\n",
    "from abc import ABCMeta, abstractmethod\n",
    "from mxnet.gluon.data.sampler import Sampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wpac4lJSgQxl"
   },
   "source": [
    "# Initialize Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "executionInfo": {
     "elapsed": 1655,
     "status": "ok",
     "timestamp": 1613396539509,
     "user": {
      "displayName": "Shikha Mallick",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjoRyV4TB5l3kSyBeE28ldIN2S1glHF3FTZvVEf_Q=s64",
      "userId": "13917264246341255180"
     },
     "user_tz": -330
    },
    "id": "8G1r73TG9lUz"
   },
   "outputs": [],
   "source": [
    "batch_size = 8   # training batch size\n",
    "batch_size_test = 8   # test batch size\n",
    "k = 5   # number of generation paths\n",
    "p = 0.8   # randomness parameter alpha\n",
    "F_e = 16    # initial hidden embedding size for each node in a graph\n",
    "F_h = [32, 64, 128, 128, 256, 256]    # output sizes of each GCN layer\n",
    "F_skip = 256    # size of skip connection layer\n",
    "F_c = [512, ]   # hidden sizes of fully connected layers after graph convolution\n",
    "Fh_policy = 128   # hidden size for policy layer\n",
    "activation = 'relu'   # activation function\n",
    "max_epochs = 10    # maximum number of epochs\n",
    "patience = 10   # how many steps in past to check test loss for early stopping\n",
    "lr = 1e-4   # initial learning rate\n",
    "decay = 0.002    # initial weight decay\n",
    "decay_step = 100    # perform weight decay after 100 steps\n",
    "clip_grad = 3.0    # gradient clipping factor\n",
    "summary_step = 200    # store model and training metrics after every 200 steps\n",
    "N_rnn = 3   # number of layers used in GRUs\n",
    "N_C = 6165   # size of pretrained protein embedding (CDGCN) or one hot encoding (Li et al.))\n",
    "is_continuous = False   # load previous model or not\n",
    "train_only = True   # train only mode or not, in train only mode validation is not done\n",
    "ckpt_dir = 'CDGCN/outputs/logs/'   # logs directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MyVlI5TngYlE"
   },
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "executionInfo": {
     "elapsed": 8894,
     "status": "ok",
     "timestamp": 1613396085863,
     "user": {
      "displayName": "Shikha Mallick",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjoRyV4TB5l3kSyBeE28ldIN2S1glHF3FTZvVEf_Q=s64",
      "userId": "13917264246341255180"
     },
     "user_tz": -330
    },
    "id": "5Z1qfqURXt7N"
   },
   "outputs": [],
   "source": [
    "def read_data(file_name):\n",
    "    smiles = []\n",
    "    with open(file_name) as f:\n",
    "        for line in f:\n",
    "            smiles.append(line.strip())\n",
    "    return smiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10246,
     "status": "ok",
     "timestamp": 1613396088085,
     "user": {
      "displayName": "Shikha Mallick",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjoRyV4TB5l3kSyBeE28ldIN2S1glHF3FTZvVEf_Q=s64",
      "userId": "13917264246341255180"
     },
     "user_tz": -330
    },
    "id": "W3-NXeK0-EMT",
    "outputId": "8b4d843b-6dde-4d9b-f32f-cb1160bbd733"
   },
   "outputs": [],
   "source": [
    "t2t_data_train = '/home/iit/CDGCN/data/bindingdb/train_dataset/train_4_org_1004_122/d3_tr_cdgcn.txt'\n",
    "dataset_train = read_data(t2t_data_train)\n",
    "if train_only == False:\n",
    "    t2t_data_test = '/home/iit/CDGCN/data/bindingdb/test_dataset/test_4_org_1004_122/d3_va_cdgcn.txt'\n",
    "    dataset_test = read_data(t2t_data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8702,
     "status": "ok",
     "timestamp": 1613396088088,
     "user": {
      "displayName": "Shikha Mallick",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjoRyV4TB5l3kSyBeE28ldIN2S1glHF3FTZvVEf_Q=s64",
      "userId": "13917264246341255180"
     },
     "user_tz": -330
    },
    "id": "T5PQ9LJBbi9_",
    "outputId": "860a28b8-b328-4d8b-e8a0-7eb0884b5aa4"
   },
   "outputs": [],
   "source": [
    "print(len(dataset_train))\n",
    "print(type(dataset_train))\n",
    "print(dataset_train[:5])\n",
    "if train_only == False:\n",
    "    print(len(dataset_test))\n",
    "    print(type(dataset_test))\n",
    "    print(dataset_test[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating dataset iterable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IterableDataset(Dataset):\n",
    "\n",
    "    __metaclass__ = ABCMeta\n",
    "\n",
    "    def __iter__(self):\n",
    "        return (self[i] for i in range(len(self)))\n",
    "\n",
    "\n",
    "class Lambda(IterableDataset):\n",
    "    \"\"\"\n",
    "    Preprocessing fn\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dataset, fn=lambda _x: _x):\n",
    "        random.seed(17)\n",
    "        random.shuffle(dataset)\n",
    "        self.dataset = dataset\n",
    "        self.fn = fn\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.fn(self.dataset[index])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating mini-batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "executionInfo": {
     "elapsed": 1348,
     "status": "ok",
     "timestamp": 1613396167320,
     "user": {
      "displayName": "Shikha Mallick",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjoRyV4TB5l3kSyBeE28ldIN2S1glHF3FTZvVEf_Q=s64",
      "userId": "13917264246341255180"
     },
     "user_tz": -330
    },
    "id": "WrVHTVVh5gmF"
   },
   "outputs": [],
   "source": [
    "class BalancedSampler(Sampler):\n",
    "\n",
    "    def __init__(self, cost, batch_size):\n",
    "        index = np.argsort(cost).tolist()\n",
    "        chunk_size = int(float(len(cost))/batch_size)\n",
    "        self.index = []\n",
    "        for i in range(batch_size):\n",
    "            self.index.append(index[i*chunk_size:(i + 1)*chunk_size])\n",
    "\n",
    "    def _g(self):\n",
    "        # shuffle data\n",
    "        for index_i in self.index:\n",
    "            random.shuffle(index_i)\n",
    "\n",
    "        for batch_index in zip(*self.index):\n",
    "            yield batch_index\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self._g()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.index[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Separating smiles and protein embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conditional(object):\n",
    "\n",
    "    __metaclass__ = ABCMeta\n",
    "\n",
    "    @abstractmethod\n",
    "    def __call__(self, *args, **kwargs):\n",
    "        raise NotImplementedError\n",
    "\n",
    "class Delimited(Conditional):\n",
    "\n",
    "    def __init__(self, d='\\t'):\n",
    "        self.d = d\n",
    "\n",
    "    def __call__(self, line):\n",
    "        line = line.strip('\\n').strip('\\r')\n",
    "        line = line.split(self.d)\n",
    "\n",
    "        smiles = line[0]\n",
    "        c = np.array([float(c_i) for c_i in line[1:]], dtype=np.float32)\n",
    "\n",
    "        return smiles, c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YJZwJjJzA6Jp"
   },
   "source": [
    "# Obtain all molecular properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "executionInfo": {
     "elapsed": 4331,
     "status": "ok",
     "timestamp": 1613396105585,
     "user": {
      "displayName": "Shikha Mallick",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjoRyV4TB5l3kSyBeE28ldIN2S1glHF3FTZvVEf_Q=s64",
      "userId": "13917264246341255180"
     },
     "user_tz": -330
    },
    "id": "aYI8y_swGSEI"
   },
   "outputs": [],
   "source": [
    "class MoleculeSpec(object):\n",
    "\n",
    "    def __init__(self, file_name='CDGCN/data/atom_types.txt'):\n",
    "        self.atom_types = []\n",
    "        self.atom_symbols = []\n",
    "        with open(file_name) as f:\n",
    "            for line in f:\n",
    "                atom_type_i = line.strip('\\n').split(',')\n",
    "                self.atom_types.append((atom_type_i[0], int(atom_type_i[1]), int(atom_type_i[2])))\n",
    "                if atom_type_i[0] not in self.atom_symbols:\n",
    "                    self.atom_symbols.append(atom_type_i[0])\n",
    "        self.bond_orders = [Chem.BondType.AROMATIC,\n",
    "                            Chem.BondType.SINGLE,\n",
    "                            Chem.BondType.DOUBLE,\n",
    "                            Chem.BondType.TRIPLE]\n",
    "        self.max_iter = 120\n",
    "\n",
    "    def get_atom_type(self, atom):\n",
    "        atom_symbol = atom.GetSymbol()\n",
    "        atom_charge = atom.GetFormalCharge()\n",
    "        atom_hs = atom.GetNumExplicitHs()\n",
    "        return self.atom_types.index((atom_symbol, atom_charge, atom_hs))\n",
    "\n",
    "    def get_bond_type(self, bond):\n",
    "        return self.bond_orders.index(bond.GetBondType())\n",
    "\n",
    "    def index_to_atom(self, idx):\n",
    "        atom_symbol, atom_charge, atom_hs = self.atom_types[idx]\n",
    "        a = Chem.Atom(atom_symbol)\n",
    "        a.SetFormalCharge(atom_charge)\n",
    "        a.SetNumExplicitHs(atom_hs)\n",
    "        return a\n",
    "\n",
    "    def index_to_bond(self, mol, begin_id, end_id, idx):\n",
    "        mol.AddBond(begin_id, end_id, self.bond_orders[idx])\n",
    "\n",
    "    @property\n",
    "    def num_atom_types(self):\n",
    "        return len(self.atom_types)\n",
    "\n",
    "    @property\n",
    "    def num_bond_types(self):\n",
    "        return len(self.bond_orders)\n",
    "\n",
    "_mol_spec = None\n",
    "\n",
    "def get_mol_spec():\n",
    "    global _mol_spec\n",
    "    if _mol_spec is None:\n",
    "        _mol_spec = MoleculeSpec()\n",
    "    return _mol_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility functions for data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "executionInfo": {
     "elapsed": 2145,
     "status": "ok",
     "timestamp": 1613396164586,
     "user": {
      "displayName": "Shikha Mallick",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjoRyV4TB5l3kSyBeE28ldIN2S1glHF3FTZvVEf_Q=s64",
      "userId": "13917264246341255180"
     },
     "user_tz": -330
    },
    "id": "Kr_byaDb0Apb"
   },
   "outputs": [],
   "source": [
    "def get_graph_from_smiles(smiles):\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "\n",
    "    # build graph\n",
    "    atom_types, atom_ranks, bonds, bond_types = [], [], [], []\n",
    "    for a, r in zip(mol.GetAtoms(), Chem.CanonicalRankAtoms(mol)):\n",
    "        atom_types.append(get_mol_spec().get_atom_type(a))\n",
    "        atom_ranks.append(r)\n",
    "    for b in mol.GetBonds():\n",
    "        idx_1, idx_2, bt = b.GetBeginAtomIdx(), b.GetEndAtomIdx(), get_mol_spec().get_bond_type(b)\n",
    "        bonds.append([idx_1, idx_2])\n",
    "        bond_types.append(bt)\n",
    "\n",
    "    # build nx graph\n",
    "    graph = nx.Graph()\n",
    "    graph.add_nodes_from(range(len(atom_types)))\n",
    "    graph.add_edges_from(bonds)\n",
    "\n",
    "    return graph, atom_types, atom_ranks, bonds, bond_types\n",
    "\n",
    "\n",
    "def get_graph_from_smiles_list(smiles_list):\n",
    "    graph_list = []\n",
    "    for smiles in smiles_list:\n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "\n",
    "        # build graph\n",
    "        atom_types, bonds, bond_types = [], [], []\n",
    "        for a in mol.GetAtoms():\n",
    "            atom_types.append(get_mol_spec().get_atom_type(a))\n",
    "        for b in mol.GetBonds():\n",
    "            idx_1, idx_2, bt = b.GetBeginAtomIdx(), b.GetEndAtomIdx(), get_mol_spec().get_bond_type(b)\n",
    "            bonds.append([idx_1, idx_2])\n",
    "            bond_types.append(bt)\n",
    "\n",
    "        X_0 = np.array(atom_types, dtype=np.int64)\n",
    "        A_0 = np.concatenate([np.array(bonds, dtype=np.int64),\n",
    "                              np.array(bond_types, dtype=np.int64)[:, np.newaxis]],\n",
    "                             axis=1)\n",
    "        graph_list.append([X_0, A_0])\n",
    "    return graph_list\n",
    "\n",
    "\n",
    "def traverse_graph(graph, atom_ranks, current_node=None, step_ids=None, p=0.9, log_p=0.0):\n",
    "    if current_node is None:\n",
    "        next_nodes = range(len(atom_ranks))\n",
    "        step_ids = [-1, ] * len(next_nodes)\n",
    "        next_node_ranks = atom_ranks\n",
    "    else:\n",
    "        next_nodes = graph.neighbors(current_node)  # get neighbor nodes\n",
    "        next_nodes = [n for n in next_nodes if step_ids[n] < 0] # filter visited nodes\n",
    "        next_node_ranks = [atom_ranks[n] for n in next_nodes] # get ranks for neighbors\n",
    "    next_nodes = [n for n, r in sorted(zip(next_nodes, next_node_ranks), key=lambda _x:_x[1])] # sort by rank\n",
    "\n",
    "    # iterate through neighbors\n",
    "    while len(next_nodes) > 0:\n",
    "        if len(next_nodes)==1:\n",
    "            next_node = next_nodes[0]\n",
    "        elif random.random() >= (1 - p):\n",
    "            next_node = next_nodes[0]\n",
    "            log_p += np.log(p)\n",
    "        else:\n",
    "            next_node = next_nodes[random.randint(1, len(next_nodes) - 1)]\n",
    "            log_p += np.log((1.0 - p) / (len(next_nodes) - 1))\n",
    "        step_ids[next_node] = max(step_ids) + 1\n",
    "        _, log_p = traverse_graph(graph, atom_ranks, next_node, step_ids, p, log_p)\n",
    "        next_nodes = [n for n in next_nodes if step_ids[n] < 0] # filter visited nodes\n",
    "\n",
    "    return step_ids, log_p\n",
    "\n",
    "\n",
    "def single_reorder(X_0, A_0, step_ids):\n",
    "    X_0, A_0 = np.copy(X_0), np.copy(A_0)\n",
    "\n",
    "    step_ids = np.array(step_ids, dtype=np.int64)\n",
    "\n",
    "    # sort by step_ids\n",
    "    sorted_ids = np.argsort(step_ids)\n",
    "    X_0 = X_0[sorted_ids]\n",
    "    A_0[:, 0], A_0[:, 1] = step_ids[A_0[:, 0]], step_ids[A_0[:, 1]]\n",
    "    max_b, min_b = np.amax(A_0[:, :2], axis=1), np.amin(A_0[:, :2], axis=1)\n",
    "    A_0 = A_0[np.lexsort([-min_b, max_b]), :]\n",
    "\n",
    "    # separate append and connect\n",
    "    max_b, min_b = np.amax(A_0[:, :2], axis=1), np.amin(A_0[:, :2], axis=1)\n",
    "    is_append = np.concatenate([np.array([True]), max_b[1:] > max_b[:-1]])\n",
    "    A_0 = np.concatenate([np.where(is_append[:, np.newaxis],\n",
    "                                 np.stack([min_b, max_b], axis=1),\n",
    "                                 np.stack([max_b, min_b], axis=1)),\n",
    "                        A_0[:, -1:]], axis=1)\n",
    "\n",
    "    return X_0, A_0\n",
    "\n",
    "\n",
    "def single_expand(X_0, A_0):\n",
    "    X_0, A_0 = np.copy(X_0), np.copy(A_0)\n",
    "\n",
    "    # expand X\n",
    "    is_append_iter = np.less(A_0[:, 0], A_0[:, 1]).astype(np.int64)\n",
    "    NX = np.cumsum(np.pad(is_append_iter, [[1, 0]], mode='constant', constant_values=1))\n",
    "    shift = np.cumsum(np.pad(NX, [[1, 0]], mode='constant')[:-1])\n",
    "    X_index = np.arange(NX.sum(), dtype=np.int64) - np.repeat(shift, NX)\n",
    "    X = X_0[X_index]\n",
    "\n",
    "    # expand A\n",
    "    _, A_index = np.tril_indices(A_0.shape[0])\n",
    "    A = A_0[A_index, :]\n",
    "    NA = np.arange(A_0.shape[0] + 1)\n",
    "\n",
    "    # get action\n",
    "    # action_type, atom_type, bond_type, append_pos, connect_pos\n",
    "    action_type = 1 - is_append_iter\n",
    "    atom_type = np.where(action_type == 0, X_0[A_0[:, 1]], 0)\n",
    "    bond_type = A_0[:, 2]\n",
    "    append_pos = np.where(action_type == 0, A_0[:, 0], 0)\n",
    "    connect_pos = np.where(action_type == 1, A_0[:, 1], 0)\n",
    "    actions = np.stack([action_type, atom_type, bond_type, append_pos, connect_pos],\n",
    "                       axis=1)\n",
    "    last_action = [[2, 0, 0, 0, 0]]\n",
    "    actions = np.append(actions, last_action, axis=0)\n",
    "\n",
    "    action_0 = np.array([X_0[0]], dtype=np.int64)\n",
    "\n",
    "    # }}}\n",
    "\n",
    "    # {{{ Get mask\n",
    "    last_atom_index = shift + NX - 1\n",
    "    last_atom_mask = np.zeros_like(X)\n",
    "    last_atom_mask[last_atom_index] = np.where(\n",
    "        np.pad(is_append_iter, [[1, 0]], mode='constant', constant_values=1) == 1,\n",
    "        np.ones_like(last_atom_index),\n",
    "        np.ones_like(last_atom_index) * 2)\n",
    "    # }}}\n",
    "\n",
    "    return action_0, X, NX, A, NA, actions, last_atom_mask\n",
    "\n",
    "\n",
    "def get_d(A, X):\n",
    "    _to_sparse = lambda _A, _X: sparse.coo_matrix((np.ones([_A.shape[0] * 2], dtype=np.int64),\n",
    "                                                   (np.concatenate([_A[:, 0], _A[:, 1]], axis=0),\n",
    "                                                    np.concatenate([_A[:, 1], _A[:, 0]], axis=0))),\n",
    "                                                  shape=[_X.shape[0], ] * 2)\n",
    "    A_sparse = _to_sparse(A, X)\n",
    "\n",
    "    d2 = A_sparse * A_sparse\n",
    "    d3 = d2 * A_sparse\n",
    "\n",
    "    # get D_2\n",
    "    D_2 = np.stack(d2.nonzero(), axis=1)\n",
    "    D_2 = D_2[D_2[:, 0] < D_2[:, 1], :]\n",
    "\n",
    "    # get D_3\n",
    "    D_3 = np.stack(d3.nonzero(), axis=1)\n",
    "    D_3 = D_3[D_3[:, 0] < D_3[:, 1], :]\n",
    "\n",
    "    # remove D_1 elements from D_3\n",
    "    D_3_sparse = _to_sparse(D_3, X)\n",
    "    D_3_sparse = D_3_sparse - D_3_sparse.multiply(A_sparse)\n",
    "    D_3 = np.stack(D_3_sparse.nonzero(), axis=1)\n",
    "    D_3 = D_3[D_3[:, 0] < D_3[:, 1], :]\n",
    "\n",
    "    return D_2, D_3\n",
    "\n",
    "\n",
    "def merge_single_0(X_0, A_0, NX_0, NA_0):\n",
    "    # shift_ids\n",
    "    cumsum = np.cumsum(np.pad(NX_0, [[1, 0]], mode='constant')[:-1])\n",
    "    A_0[:, :2] += np.stack([np.repeat(cumsum, NA_0), ] * 2, axis=1)\n",
    "\n",
    "    # get D\n",
    "    D_0_2, D_0_3 = get_d(A_0, X_0)\n",
    "\n",
    "    # split A\n",
    "    A_split = []\n",
    "    for i in range(get_mol_spec().num_bond_types):\n",
    "        A_i = A_0[A_0[:, 2] == i, :2]\n",
    "        A_split.append(A_i)\n",
    "    A_split.extend([D_0_2, D_0_3])\n",
    "    A_0 = A_split\n",
    "\n",
    "    # NX_rep\n",
    "    NX_rep_0 = np.repeat(np.arange(NX_0.shape[0]), NX_0)\n",
    "\n",
    "    return X_0, A_0, NX_0, NX_rep_0\n",
    "\n",
    "\n",
    "def merge_single(X, A,\n",
    "                 NX, NA,\n",
    "                 mol_ids, rep_ids, iw_ids,\n",
    "                 action_0, actions,\n",
    "                 last_append_mask,\n",
    "                 log_p):\n",
    "    X, A, NX, NX_rep = merge_single_0(X, A, NX, NA)\n",
    "    cumsum = np.cumsum(np.pad(NX, [[1, 0]], mode='constant')[:-1])\n",
    "    actions[:, -2] += cumsum * (actions[:, 0] == 0)\n",
    "    actions[:, -1] += cumsum * (actions[:, 0] == 1)\n",
    "    mol_ids_rep = np.repeat(mol_ids, NX)\n",
    "    rep_ids_rep = np.repeat(rep_ids, NX)\n",
    "\n",
    "    return X, A,\\\n",
    "           mol_ids_rep, rep_ids_rep, iw_ids,\\\n",
    "           last_append_mask,\\\n",
    "           NX, NX_rep,\\\n",
    "           action_0, actions, \\\n",
    "           log_p\n",
    "\n",
    "def process_single(smiles, k, p):\n",
    "    graph, atom_types, atom_ranks, bonds, bond_types = get_graph_from_smiles(smiles)\n",
    "\n",
    "    # original\n",
    "    X_0 = np.array(atom_types, dtype=np.int64)\n",
    "    A_0 = np.concatenate([np.array(bonds, dtype=np.int64),\n",
    "                          np.array(bond_types, dtype=np.int64)[:, np.newaxis]],\n",
    "                         axis=1)\n",
    "\n",
    "    X, A = [], []\n",
    "    NX, NA = [], []\n",
    "    mol_ids, rep_ids, iw_ids = [], [], []\n",
    "    action_0, actions = [], []\n",
    "    last_append_mask = []\n",
    "    log_p = []\n",
    "\n",
    "    # sampling generation paths\n",
    "    for i in range(k):\n",
    "        step_ids_i, log_p_i = traverse_graph(graph, atom_ranks, p=p)\n",
    "        X_i, A_i = single_reorder(X_0, A_0, step_ids_i)\n",
    "        action_0_i, X_i, NX_i, A_i, NA_i, actions_i, last_atom_mask_i = single_expand(X_i, A_i)\n",
    "\n",
    "        # appends\n",
    "        X.append(X_i)\n",
    "        A.append(A_i)\n",
    "        NX.append(NX_i)\n",
    "        NA.append(NA_i)\n",
    "        action_0.append(action_0_i)\n",
    "        actions.append(actions_i)\n",
    "        last_append_mask.append(last_atom_mask_i)\n",
    "\n",
    "        mol_ids.append(np.zeros_like(NX_i, dtype=np.int64))\n",
    "        rep_ids.append(np.ones_like(NX_i, dtype=np.int64) * i)\n",
    "        iw_ids.append(np.ones_like(NX_i, dtype=np.int64) * i)\n",
    "\n",
    "        log_p.append(log_p_i)\n",
    "\n",
    "    # concatenate\n",
    "    X = np.concatenate(X, axis=0)\n",
    "    A = np.concatenate(A, axis = 0)\n",
    "    NX = np.concatenate(NX, axis = 0)\n",
    "    NA = np.concatenate(NA, axis = 0)\n",
    "    action_0 = np.concatenate(action_0, axis = 0)\n",
    "    actions = np.concatenate(actions, axis = 0)\n",
    "    last_append_mask = np.concatenate(last_append_mask, axis = 0)\n",
    "    mol_ids = np.concatenate(mol_ids, axis = 0)\n",
    "    rep_ids = np.concatenate(rep_ids, axis = 0)\n",
    "    iw_ids = np.concatenate(iw_ids, axis = 0)\n",
    "    log_p = np.array(log_p, dtype=np.float32)\n",
    "\n",
    "    return X, A, NX, NA, mol_ids, rep_ids, iw_ids, action_0, actions, last_append_mask, log_p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ofH-B-Wg6HMf"
   },
   "source": [
    "# Loading data on GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "executionInfo": {
     "elapsed": 1650,
     "status": "ok",
     "timestamp": 1613396168179,
     "user": {
      "displayName": "Shikha Mallick",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjoRyV4TB5l3kSyBeE28ldIN2S1glHF3FTZvVEf_Q=s64",
      "userId": "13917264246341255180"
     },
     "user_tz": -330
    },
    "id": "lKHpGShB7Nhh"
   },
   "outputs": [],
   "source": [
    "class MolLoader(DataLoader):\n",
    "    \"\"\"Load graph based molecule representation from SMILES\"\"\"\n",
    "    def __init__(self, dataset, batch_size=10, num_workers=0,\n",
    "                 k=10, p=0.9, shuffle=False, sampler=None, batch_sampler=None):\n",
    "        self.k = k\n",
    "        self.p = p\n",
    "\n",
    "        # batch_sampler, sampler and shuffle are mutually exclusive\n",
    "        if batch_sampler is not None:\n",
    "            super(MolLoader, self).__init__(dataset, batch_sampler=batch_sampler,\n",
    "                                            num_workers=num_workers, batchify_fn=self._collate_fn)\n",
    "        elif sampler is not None:\n",
    "            super(MolLoader, self).__init__(dataset, sampler=sampler,\n",
    "                                            num_workers=num_workers, batchify_fn=self._collate_fn,\n",
    "                                            last_batch='rollover')\n",
    "        else:\n",
    "            super(MolLoader, self).__init__(dataset, batch_size, shuffle=shuffle,\n",
    "                                            num_workers=num_workers, batchify_fn=self._collate_fn,\n",
    "                                            last_batch='rollover')\n",
    "\n",
    "\n",
    "    def _collate_fn(self, batch):\n",
    "        # names = X, A,\n",
    "        #         NX, NA,\n",
    "        #         mol_ids, rep_ids, iw_ids,\n",
    "        #         action_0, actions,\n",
    "        #         last_append_mask,\n",
    "        #         log_p\n",
    "\n",
    "        shapes = [[0], [0, 3],\n",
    "                  [0], [0],\n",
    "                  [0], [0], [0],\n",
    "                  [0], [0, 5],\n",
    "                  [0],\n",
    "                  [0]]\n",
    "        dtypes = [np.int64, np.int64,\n",
    "                  np.int64, np.int64,\n",
    "                  np.int64, np.int64, np.int64,\n",
    "                  np.int64, np.int64,\n",
    "                  np.int64,\n",
    "                  np.float32]\n",
    "\n",
    "        _build = lambda: [np.zeros(shape=s, dtype=d) for s, d in zip(shapes, dtypes)]\n",
    "        _append = lambda _r0, _r1: [np.concatenate([__r0, __r1], axis=0)\n",
    "                                    for __r0, __r1 in zip(_r0, _r1)]\n",
    "\n",
    "        X, A, \\\n",
    "        NX, NA, \\\n",
    "        mol_ids, rep_ids, iw_ids, \\\n",
    "        action_0, actions, \\\n",
    "        last_append_mask, \\\n",
    "        log_p = _build()\n",
    "\n",
    "\n",
    "        for i, record_in in enumerate(batch):\n",
    "            smiles = record_in\n",
    "\n",
    "            X_i, A_i, \\\n",
    "            NX_i, NA_i, \\\n",
    "            mol_ids_i, rep_ids_i, iw_ids_i, \\\n",
    "            action_0_i, actions_i, \\\n",
    "            last_append_mask_i, log_p_i = process_single(smiles, self.k, self.p)\n",
    "\n",
    "            if i != 0:\n",
    "                mol_ids_i += mol_ids[-1] + 1\n",
    "                iw_ids_i += iw_ids[-1] + 1\n",
    "\n",
    "            X, A, \\\n",
    "            NX, NA, \\\n",
    "            mol_ids, rep_ids, iw_ids, \\\n",
    "            action_0, actions, \\\n",
    "            last_append_mask, \\\n",
    "            log_p = _append([X, A,\n",
    "                             NX, NA,\n",
    "                             mol_ids, rep_ids, iw_ids,\n",
    "                             action_0, actions,\n",
    "                             last_append_mask,\n",
    "                             log_p],\n",
    "                            [X_i, A_i,\n",
    "                             NX_i, NA_i,\n",
    "                             mol_ids_i, rep_ids_i, iw_ids_i,\n",
    "                             action_0_i, actions_i,\n",
    "                             last_append_mask_i,\n",
    "                             log_p_i])\n",
    "\n",
    "        X, A, \\\n",
    "        mol_ids_rep, rep_ids_rep, iw_ids, \\\n",
    "        last_append_mask, \\\n",
    "        NX, NX_rep, \\\n",
    "        action_0, actions, \\\n",
    "        log_p = merge_single(X, A,\n",
    "                                   NX, NA,\n",
    "                                   mol_ids, rep_ids, iw_ids,\n",
    "                                   action_0, actions,\n",
    "                                   last_append_mask,\n",
    "                                   log_p)\n",
    "\n",
    "        result_out = [X, A,\n",
    "                      mol_ids_rep, rep_ids_rep, iw_ids,\n",
    "                      last_append_mask,\n",
    "                      NX, NX_rep,\n",
    "                      action_0, actions,\n",
    "                      log_p]\n",
    "\n",
    "        return result_out\n",
    "\n",
    "    @staticmethod\n",
    "    def from_numpy_to_tensor(record):\n",
    "        \"\"\"Convert numpy to tensor and place it to a specific device\"\"\"\n",
    "        [X, A,\n",
    "         mol_ids_rep, rep_ids_rep, iw_ids,\n",
    "         last_append_mask,\n",
    "         NX, NX_rep,\n",
    "         action_0, actions,\n",
    "         log_p] = record\n",
    "\n",
    "        X = nd.array(X, ctx=mx.gpu(), dtype='int64')\n",
    "        A_sparse = []\n",
    "        for A_i in A:\n",
    "            if A_i.shape[0] == 0:\n",
    "                A_sparse.append(None)\n",
    "            else:\n",
    "                # transpose may not be supported in gpu\n",
    "                A_i = np.concatenate([A_i, A_i[:, [1, 0]]], axis=0)\n",
    "\n",
    "                # construct csr matrix ...\n",
    "                data = np.ones((A_i.shape[0], ), dtype=np.float32)\n",
    "                row, col = A_i[:, 0], A_i[:, 1]\n",
    "                A_sparse_i = nd.sparse.csr_matrix((data, (row, col)),\n",
    "                                                  shape=tuple([int(X.shape[0]), ]*2),\n",
    "                                                  ctx=mx.gpu(),\n",
    "                                                  dtype='float32')\n",
    "\n",
    "                # append to list\n",
    "                A_sparse.append(A_sparse_i)\n",
    "\n",
    "        batch_size, iw_size = (mol_ids_rep.max() + 1).item(), \\\n",
    "                              (rep_ids_rep.max() + 1).item()\n",
    "\n",
    "        mol_ids_rep, rep_ids_rep, iw_ids, \\\n",
    "        last_append_mask, \\\n",
    "        NX, NX_rep, action_0, actions = [nd.array(_x, ctx=mx.gpu(), dtype='int64')\n",
    "                                         for _x in [mol_ids_rep, rep_ids_rep, iw_ids,\n",
    "                                                    last_append_mask,\n",
    "                                                    NX, NX_rep, action_0, actions]]\n",
    "\n",
    "        log_p = nd.array(log_p, ctx=mx.gpu(), dtype='float32')\n",
    "\n",
    "        record = [X, A_sparse, iw_ids, last_append_mask,\n",
    "                  NX, NX_rep, action_0, actions, log_p,\n",
    "                  batch_size, iw_size]\n",
    "\n",
    "\n",
    "        return record\n",
    "\n",
    "\n",
    "class MolRNNLoader(MolLoader):\n",
    "\n",
    "    def _collate_fn(self, batch):\n",
    "        result_out = super(MolRNNLoader, self)._collate_fn(batch)\n",
    "\n",
    "        # things ready for rnn\n",
    "        mol_list = [Chem.MolFromSmiles(batch_i) for batch_i in batch]\n",
    "        # preparing mapping\n",
    "        graph_to_rnn = np.zeros((len(batch), self.k, get_mol_spec().max_iter), dtype=np.int64)\n",
    "        rnn_to_graph = []\n",
    "        cum_sum = 0\n",
    "        for i, mol_i in enumerate(mol_list):\n",
    "            num_iter = mol_i.GetNumBonds() + 1\n",
    "            for k in range(self.k):\n",
    "                graph_to_rnn[i, k, :num_iter] = (np.arange(num_iter) + cum_sum)\n",
    "\n",
    "                rnn_to_graph_0 = np.ones([num_iter,], dtype=np.int64) * i\n",
    "                rnn_to_graph_1 = np.ones_like(rnn_to_graph_0) * k\n",
    "                rnn_to_graph_2 = np.arange(num_iter)\n",
    "                rnn_to_graph.append(np.stack([rnn_to_graph_0, rnn_to_graph_1, rnn_to_graph_2], axis=0))\n",
    "\n",
    "                cum_sum += num_iter\n",
    "        rnn_to_graph = np.concatenate(rnn_to_graph, axis=1)\n",
    "        NX_cum = np.cumsum(result_out[6])\n",
    "\n",
    "        result_out = result_out + [graph_to_rnn, rnn_to_graph, NX_cum]\n",
    "\n",
    "        return result_out\n",
    "\n",
    "    @staticmethod\n",
    "    def from_numpy_to_tensor(record):\n",
    "        [X, A,\n",
    "         mol_ids_rep, rep_ids_rep, iw_ids,\n",
    "         last_append_mask,\n",
    "         NX, NX_rep,\n",
    "         action_0, actions,\n",
    "         log_p,\n",
    "         graph_to_rnn, rnn_to_graph, NX_cum] = record\n",
    "\n",
    "        output = MolLoader.from_numpy_to_tensor([X, A,\n",
    "                                                 mol_ids_rep, rep_ids_rep, iw_ids,\n",
    "                                                 last_append_mask,\n",
    "                                                 NX, NX_rep,\n",
    "                                                 action_0, actions,\n",
    "                                                 log_p])\n",
    "\n",
    "        graph_to_rnn, rnn_to_graph, NX_cum =\\\n",
    "            nd.array(graph_to_rnn, ctx=mx.gpu(), dtype='int64'),\\\n",
    "            nd.array(rnn_to_graph, ctx=mx.gpu(), dtype='int64'), \\\n",
    "            nd.array(NX_cum, ctx=mx.gpu(), dtype='int64')\n",
    "\n",
    "        output = output + [graph_to_rnn, rnn_to_graph, NX_cum]\n",
    "\n",
    "        return output\n",
    "    \n",
    "class CMolRNNLoader(MolRNNLoader):\n",
    "\n",
    "    def __init__(self, dataset, batch_size=10, num_workers=0,\n",
    "                 k=10, p=0.9, shuffle=False, sampler=None, batch_sampler=None,\n",
    "                 conditional=None):\n",
    "        if conditional is None:\n",
    "            raise ValueError('Conditional function is not set, '\n",
    "                             'use unconditional version instead')\n",
    "        if not callable(conditional):\n",
    "            raise TypeError('Provided condition is not callable')\n",
    "\n",
    "        self.conditional = conditional\n",
    "\n",
    "        super(CMolRNNLoader, self).__init__(dataset, batch_size, num_workers,\n",
    "                                            k, p, shuffle, sampler, batch_sampler)\n",
    "\n",
    "    def _collate_fn(self, batch):\n",
    "        smiles_list, c = [], []\n",
    "        for record_i in batch:\n",
    "            smiles_i, c_i = self.conditional(record_i)\n",
    "            smiles_list.append(smiles_i)\n",
    "            c.append(c_i)\n",
    "        c = np.stack(c, axis=0)\n",
    "\n",
    "        output = super(CMolRNNLoader, self)._collate_fn(smiles_list)\n",
    "        output.append(c)\n",
    "\n",
    "        return output\n",
    "\n",
    "    @staticmethod\n",
    "    def from_numpy_to_tensor(record):\n",
    "        [X, A,\n",
    "         mol_ids_rep, rep_ids_rep, iw_ids,\n",
    "         last_append_mask,\n",
    "         NX, NX_rep,\n",
    "         action_0, actions,\n",
    "         log_p,\n",
    "         graph_to_rnn, rnn_to_graph, NX_cum,\n",
    "         c] = record\n",
    "\n",
    "        output = MolRNNLoader.from_numpy_to_tensor([X, A,\n",
    "                                                    mol_ids_rep, rep_ids_rep, iw_ids,\n",
    "                                                    last_append_mask,\n",
    "                                                    NX, NX_rep,\n",
    "                                                    action_0, actions,\n",
    "                                                    log_p,\n",
    "                                                    graph_to_rnn, rnn_to_graph, NX_cum])\n",
    "        ids = nd.array(mol_ids_rep, ctx=mx.gpu(), dtype='int64')\n",
    "\n",
    "        c = nd.array(c, ctx=mx.gpu(), dtype='float32')\n",
    "\n",
    "        output = output + [c, ids]\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining graph convolution and other functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "executionInfo": {
     "elapsed": 2407,
     "status": "ok",
     "timestamp": 1613396170945,
     "user": {
      "displayName": "Shikha Mallick",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjoRyV4TB5l3kSyBeE28ldIN2S1glHF3FTZvVEf_Q=s64",
      "userId": "13917264246341255180"
     },
     "user_tz": -330
    },
    "id": "L53rlixAICeU"
   },
   "outputs": [],
   "source": [
    "class GraphConvFn(Function):\n",
    "\n",
    "    def __init__(self, A):\n",
    "        self.A = A # type: nd.sparse.CSRNDArray\n",
    "        self.A_T = self.A # assume symmetric\n",
    "        super(GraphConvFn, self).__init__()\n",
    "\n",
    "    def forward(self, X):\n",
    "        if self.A is not None:\n",
    "            if len(X.shape) > 2:\n",
    "                X_resized = X.reshape((X.shape[0], -1))\n",
    "                output = nd.sparse.dot(self.A, X_resized)\n",
    "                output = output.reshape([-1, ] + [X.shape[i] for i in range(1, len(X.shape))])\n",
    "            else:\n",
    "                output = nd.sparse.dot(self.A, X)\n",
    "            return output\n",
    "        else:\n",
    "            return nd.zeros_like(X)\n",
    "\n",
    "    def backward(self, grad_output):\n",
    "\n",
    "        if self.A is not None:\n",
    "            if len(grad_output.shape) > 2:\n",
    "                grad_output_resized = grad_output.reshape((grad_output.shape[0], -1))\n",
    "                grad_input = nd.sparse.dot(self.A_T, grad_output_resized)\n",
    "                grad_input = grad_input.reshape([-1] + [grad_output.shape[i]\n",
    "                                                        for i in range(1, len(grad_output.shape))])\n",
    "            else:\n",
    "                grad_input = nd.sparse.dot(self.A_T, grad_output)\n",
    "            return grad_input\n",
    "        else:\n",
    "            return nd.zeros_like(grad_output)\n",
    "\n",
    "\n",
    "class EfficientGraphConvFn(Function):\n",
    "    \"\"\"Save memory by re-computation\"\"\"\n",
    "\n",
    "    def __init__(self, A_list):\n",
    "        self.A_list = A_list\n",
    "        super(EfficientGraphConvFn, self).__init__()\n",
    "\n",
    "    def forward(self, X, W):\n",
    "        X_list = [X]\n",
    "        for A in self.A_list:\n",
    "            if A is not None:\n",
    "                X_list.append(nd.sparse.dot(A, X))\n",
    "            else:\n",
    "                X_list.append(nd.zeros_like(X))\n",
    "        X_out = nd.concat(*X_list, dim=1)\n",
    "        self.save_for_backward(X, W)\n",
    "\n",
    "        return nd.dot(X_out, W)\n",
    "\n",
    "    def backward(self, grad_output):\n",
    "        X, W = self.saved_tensors\n",
    "\n",
    "        # recompute X_out\n",
    "        X_list = [X, ]\n",
    "        for A in self.A_list:\n",
    "            if A is not None:\n",
    "                X_list.append(nd.sparse.dot(A, X))\n",
    "            else:\n",
    "                X_list.append(nd.zeros_like(X))\n",
    "        X_out = nd.concat(*X_list, dim=1)\n",
    "\n",
    "        grad_W = nd.dot(X_out.T, grad_output)\n",
    "\n",
    "        grad_X_out = nd.dot(grad_output, W.T)\n",
    "        grad_X_out_list = nd.split(grad_X_out, num_outputs=len(self.A_list) + 1)\n",
    "\n",
    "\n",
    "        grad_X = [grad_X_out_list[0], ]\n",
    "        for A, grad_X_out in zip(self.A_list, grad_X_out_list[1:]):\n",
    "            if A is not None:\n",
    "                grad_X.append(nd.sparse.dot(A, grad_X_out))\n",
    "            else:\n",
    "                grad_X.append(nd.zeros_like(grad_X_out))\n",
    "\n",
    "        grad_X = sum(grad_X)\n",
    "\n",
    "        return grad_X, grad_W\n",
    "\n",
    "\n",
    "class SegmentSumFn(GraphConvFn):\n",
    "\n",
    "    def __init__(self, idx, num_seg):\n",
    "        # build A\n",
    "        # construct coo\n",
    "        data = nd.ones(idx.shape[0], ctx=idx.context, dtype='int64')\n",
    "        row, col = idx, nd.arange(idx.shape[0], ctx=idx.context, dtype='int64')\n",
    "        shape = (num_seg, int(idx.shape[0]))\n",
    "        sparse = nd.sparse.csr_matrix((data, (row, col)), shape=shape,\n",
    "                                      ctx=idx.context, dtype='float32')\n",
    "        super(SegmentSumFn, self).__init__(sparse)\n",
    "\n",
    "        sparse = nd.sparse.csr_matrix((data, (col, row)), shape=(shape[1], shape[0]),\n",
    "                                      ctx=idx.context, dtype='float32')\n",
    "        self.A_T = sparse\n",
    "\n",
    "\n",
    "def squeeze(input, axis):\n",
    "    assert input.shape[axis] == 1\n",
    "\n",
    "    new_shape = list(input.shape)\n",
    "    del new_shape[axis]\n",
    "\n",
    "    return input.reshape(new_shape)\n",
    "\n",
    "\n",
    "def unsqueeze(input, axis):\n",
    "    return nd.expand_dims(input, axis=axis)\n",
    "\n",
    "\n",
    "def logsumexp(inputs, axis=None, keepdims=False):\n",
    "    \"\"\"Numerically stable logsumexp.\n",
    "    Args:\n",
    "        inputs: A Variable with any shape.\n",
    "        axis: An integer.\n",
    "        keepdims: A boolean.\n",
    "    Returns:\n",
    "        Equivalent of log(sum(exp(inputs), dim=dim, keepdim=keepdim)).\n",
    "    Adopted from: https://github.com/pytorch/pytorch/issues/2591\n",
    "    \"\"\"\n",
    "    # For a 1-D array x (any array along a single dimension),\n",
    "    # log sum exp(x) = s + log sum exp(x - s)\n",
    "    # with s = max(x) being a common choice.\n",
    "    if axis is None:\n",
    "        inputs = inputs.reshape([-1])\n",
    "        axis = 0\n",
    "    s = nd.max(inputs, axis=axis, keepdims=True)\n",
    "    outputs = s + (inputs - s).exp().sum(axis=axis, keepdims=True).log()\n",
    "    if not keepdims:\n",
    "        outputs = nd.sum(outputs, axis=axis, keepdims=False)\n",
    "    return outputs\n",
    "\n",
    "\n",
    "def get_activation(name):\n",
    "    activation_dict = {\n",
    "        'relu':nd.relu,\n",
    "        'tanh':nd.tanh\n",
    "    }\n",
    "    return activation_dict[name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "executionInfo": {
     "elapsed": 2359,
     "status": "ok",
     "timestamp": 1613396170398,
     "user": {
      "displayName": "Shikha Mallick",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjoRyV4TB5l3kSyBeE28ldIN2S1glHF3FTZvVEf_Q=s64",
      "userId": "13917264246341255180"
     },
     "user_tz": -330
    },
    "id": "L6W61n2LKi8S"
   },
   "outputs": [],
   "source": [
    "class Linear_BN(nn.Sequential):\n",
    "    def __init__(self, F_in, F_out):\n",
    "        super(Linear_BN, self).__init__()\n",
    "        self.add(nn.Dense(F_out, in_units=F_in, use_bias=False))\n",
    "        self.add(BatchNorm(in_channels=F_out))\n",
    "\n",
    "\n",
    "class GraphConv(nn.Block):\n",
    "\n",
    "    def __init__(self, Fin, Fout, D):\n",
    "        super(GraphConv, self).__init__()\n",
    "\n",
    "        # model settings\n",
    "        self.Fin = Fin\n",
    "        self.Fout = Fout\n",
    "        self.D = D\n",
    "\n",
    "        # model parameters\n",
    "        self.W = self.params.get('w', shape=(self.Fin * (self.D + 1), self.Fout),\n",
    "                                 init=None, allow_deferred_init=False)\n",
    "\n",
    "    def forward(self, X, A_list):\n",
    "        try:\n",
    "            assert len(A_list) == self.D\n",
    "        except AssertionError as e:\n",
    "            print(self.D, len(A_list))\n",
    "            raise e\n",
    "        return EfficientGraphConvFn(A_list)(X, self.W.data(X.context))\n",
    "\n",
    "\n",
    "class Policy(nn.Block):\n",
    "\n",
    "    def __init__(self, F_in, F_h, N_A, N_B, k=1):\n",
    "        super(Policy, self).__init__()\n",
    "        self.F_in = F_in # number of input features for each atom\n",
    "        self.F_h = F_h # number of context variables\n",
    "        self.N_A = N_A # number of atom types\n",
    "        self.N_B = N_B # number of bond types\n",
    "        self.k = k # number of softmax used in the mixture\n",
    "\n",
    "\n",
    "        with self.name_scope():\n",
    "            self.linear_h = Linear_BN(F_in * 2, self.F_h * k)\n",
    "            self.linear_h_t = Linear_BN(F_in, self.F_h * k)\n",
    "\n",
    "            self.linear_x = nn.Dense(self.N_B + self.N_B*self.N_A, in_units=self.F_h)\n",
    "            self.linear_x_t = nn.Dense(1, in_units=self.F_h)\n",
    "\n",
    "            if self.k > 1:\n",
    "                self.linear_pi = nn.Dense(self.k, in_units=self.F_in)\n",
    "            else:\n",
    "                self.linear_pi = None\n",
    "\n",
    "    def forward(self, X, NX, NX_rep, X_end=None):\n",
    "        # segment mean for X\n",
    "        if X_end is None:\n",
    "            X_end = SegmentSumFn(NX_rep, NX.shape[0])(X)/nd.cast(fn.unsqueeze(NX, 1), 'float32')\n",
    "        X = nd.concat(X, X_end[NX_rep, :], dim=1)\n",
    "\n",
    "        X_h = nd.relu(self.linear_h(X)).reshape([-1, self.F_h])\n",
    "        X_h_end = nd.relu(self.linear_h_t(X_end)).reshape([-1, self.F_h])\n",
    "\n",
    "        X_x = nd.exp(self.linear_x(X_h)).reshape([-1, self.k, self.N_B + self.N_B*self.N_A])\n",
    "        X_x_end = nd.exp(self.linear_x_t(X_h_end)).reshape([-1, self.k, 1])\n",
    "\n",
    "        X_sum = nd.sum(SegmentSumFn(NX_rep, NX.shape[0])(X_x), -1, keepdims=True) + X_x_end\n",
    "        X_sum_gathered = X_sum[NX_rep, :, :]\n",
    "\n",
    "        X_softmax = X_x / X_sum_gathered\n",
    "        X_softmax_end = X_x_end/ X_sum\n",
    "\n",
    "        if self.k > 1:\n",
    "            pi = unsqueeze(nd.softmax(self.linear_pi(X_end), axis=1), -1)\n",
    "            pi_gathered = pi[NX_rep, :, :]\n",
    "\n",
    "            X_softmax = nd.sum(X_softmax * pi_gathered, axis=1)\n",
    "            X_softmax_end = nd.sum(X_softmax_end * pi, axis=1)\n",
    "        else:\n",
    "            X_softmax = squeeze(X_softmax, 1)\n",
    "            X_softmax_end = squeeze(X_softmax_end, 1)\n",
    "\n",
    "        # generate output probabilities\n",
    "        connect, append = X_softmax[:, :self.N_B], X_softmax[:, self.N_B:]\n",
    "        append = append.reshape([-1, self.N_A, self.N_B])\n",
    "        end = squeeze(X_softmax_end, -1)\n",
    "\n",
    "        return append, connect, end\n",
    "\n",
    "\n",
    "class BatchNorm(nn.Block):\n",
    "\n",
    "    def __init__(self, in_channels, momentum=0.9, eps=1e-5):\n",
    "        super(BatchNorm, self).__init__()\n",
    "        self.F = in_channels\n",
    "\n",
    "        self.bn_weight = self.params.get('bn_weight', shape=(self.F,), init=mx.init.One(),\n",
    "                                         allow_deferred_init=False)\n",
    "        self.bn_bias = self.params.get('bn_bias', shape=(self.F,), init=mx.init.Zero(),\n",
    "                                       allow_deferred_init=False)\n",
    "\n",
    "        self.running_mean = self.params.get('running_mean', grad_req='null',\n",
    "                                            shape=(self.F,),\n",
    "                                            init=mx.init.Zero(),\n",
    "                                            allow_deferred_init=False,\n",
    "                                            differentiable=False)\n",
    "        self.running_var = self.params.get('running_var', grad_req='null',\n",
    "                                           shape=(self.F,),\n",
    "                                           init=mx.init.One(),\n",
    "                                           allow_deferred_init=False,\n",
    "                                           differentiable=False)\n",
    "        self.momentum = momentum\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x):\n",
    "        if autograd.is_training():\n",
    "            return nd.BatchNorm(x,\n",
    "                                gamma=self.bn_weight.data(x.context),\n",
    "                                beta=self.bn_bias.data(x.context),\n",
    "                                moving_mean=self.running_mean.data(x.context),\n",
    "                                moving_var=self.running_var.data(x.context),\n",
    "                                eps=self.eps, momentum=self.momentum,\n",
    "                                use_global_stats=False)\n",
    "        else:\n",
    "            return nd.BatchNorm(x,\n",
    "                                gamma=self.bn_weight.data(x.context),\n",
    "                                beta=self.bn_bias.data(x.context),\n",
    "                                moving_mean=self.running_mean.data(x.context),\n",
    "                                moving_var=self.running_var.data(x.context),\n",
    "                                eps=self.eps, momentum=self.momentum,\n",
    "                                use_global_stats=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "executionInfo": {
     "elapsed": 1789,
     "status": "ok",
     "timestamp": 1613396170946,
     "user": {
      "displayName": "Shikha Mallick",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjoRyV4TB5l3kSyBeE28ldIN2S1glHF3FTZvVEf_Q=s64",
      "userId": "13917264246341255180"
     },
     "user_tz": -330
    },
    "id": "ZkogfBJ8BxQF"
   },
   "source": [
    "# Building generative network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MoleculeGenerator(nn.Block):\n",
    "\n",
    "    __metaclass__ = ABCMeta\n",
    "\n",
    "    def __init__(self, N_A, N_B, D, F_e, F_skip, F_c, Fh_policy, activation,\n",
    "                 *args, **kwargs):\n",
    "        super(MoleculeGenerator, self).__init__()\n",
    "        self.N_A = N_A\n",
    "        self.N_B = N_B\n",
    "        self.D = D\n",
    "        self.F_e = F_e\n",
    "        self.F_skip = F_skip\n",
    "        self.F_c = list(F_c) if isinstance(F_c, tuple) else F_c\n",
    "        self.Fh_policy = Fh_policy\n",
    "        self.activation = get_activation(activation)\n",
    "\n",
    "        with self.name_scope():\n",
    "            # embeddings\n",
    "            self.embedding_atom = nn.Embedding(self.N_A, self.F_e)\n",
    "            self.embedding_mask = nn.Embedding(3, self.F_e)\n",
    "\n",
    "            # graph conv\n",
    "            self._build_graph_conv(*args, **kwargs)\n",
    "\n",
    "            # fully connected\n",
    "            self.dense = nn.Sequential()\n",
    "            for i, (f_in, f_out) in enumerate(zip([self.F_skip, ] + self.F_c[:-1], self.F_c)):\n",
    "                self.dense.add(Linear_BN(f_in, f_out))\n",
    "\n",
    "            # policy\n",
    "            self.policy_0 = self.params.get('policy_0', shape=[self.N_A, ],\n",
    "                                            init=mx.init.Zero(),\n",
    "                                            allow_deferred_init=False)\n",
    "            self.policy_h = Policy(self.F_c[-1], self.Fh_policy, self.N_A, self.N_B)\n",
    "\n",
    "        self.mode = 'loss'\n",
    "\n",
    "    @abstractmethod\n",
    "    def _build_graph_conv(self, *args, **kwargs):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    @abstractmethod\n",
    "    def _graph_conv_forward(self, X, A):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def _policy_0(self, ctx):\n",
    "        policy_0 = nd.exp(self.policy_0.data(ctx))\n",
    "        policy_0 = policy_0/policy_0.sum()\n",
    "        return policy_0\n",
    "\n",
    "    def _policy(self, X, A, NX, NX_rep, last_append_mask):\n",
    "        # get initial embedding\n",
    "        X = self.embedding_atom(X) + self.embedding_mask(last_append_mask)\n",
    "\n",
    "        # convolution\n",
    "        X = self._graph_conv_forward(X, A)\n",
    "\n",
    "        # linear\n",
    "        X = self.dense(X)\n",
    "\n",
    "        # policy\n",
    "        append, connect, end = self.policy_h(X, NX, NX_rep)\n",
    "\n",
    "        return append, connect, end\n",
    "\n",
    "    def _likelihood(self, init, append, connect, end,\n",
    "                    action_0, actions, iw_ids, log_p_sigma,\n",
    "                    batch_size, iw_size):\n",
    "\n",
    "        # decompose action:\n",
    "        action_type, node_type, edge_type, append_pos, connect_pos = \\\n",
    "            actions[:, 0], actions[:, 1], actions[:, 2], actions[:, 3], actions[:, 4]\n",
    "        _log_mask = lambda _x, _mask: _mask * nd.log(_x + 1e-10) + (1- _mask) * nd.zeros_like(_x)\n",
    "\n",
    "        # init\n",
    "        init = init.reshape([batch_size * iw_size, self.N_A])\n",
    "        index = nd.stack(nd.arange(action_0.shape[0], ctx=action_0.context, dtype='int64'), action_0, axis=0)\n",
    "        loss_init = nd.log(nd.gather_nd(init, index) + 1e-10)\n",
    "\n",
    "        # end\n",
    "        loss_end = _log_mask(end, nd.cast(action_type == 2, 'float32'))\n",
    "\n",
    "        # append\n",
    "        index = nd.stack(append_pos, node_type, edge_type, axis=0)\n",
    "        loss_append = _log_mask(nd.gather_nd(append, index), nd.cast(action_type == 0, 'float32'))\n",
    "\n",
    "        # connect\n",
    "        index = nd.stack(connect_pos, edge_type, axis=0)\n",
    "        loss_connect = _log_mask(nd.gather_nd(connect, index), nd.cast(action_type == 1, 'float32'))\n",
    "\n",
    "        # sum up results\n",
    "        log_p_x = loss_end + loss_append + loss_connect\n",
    "        log_p_x = squeeze(SegmentSumFn(iw_ids, batch_size*iw_size)(unsqueeze(log_p_x, -1)), -1)\n",
    "        log_p_x = log_p_x + loss_init\n",
    "\n",
    "        # reshape\n",
    "        log_p_x = log_p_x.reshape([batch_size, iw_size])\n",
    "        log_p_sigma = log_p_sigma.reshape([batch_size, iw_size])\n",
    "        l = log_p_x - log_p_sigma\n",
    "        l = logsumexp(l, axis=1) - math.log(float(iw_size))\n",
    "        return l\n",
    "\n",
    "    def forward(self, *input):\n",
    "        if self.mode=='loss' or self.mode=='likelihood':\n",
    "            X, A, iw_ids, last_append_mask, \\\n",
    "            NX, NX_rep, action_0, actions, log_p, \\\n",
    "            batch_size, iw_size = input\n",
    "\n",
    "            init = self._policy_0(X.context).tile([batch_size * iw_size, 1])\n",
    "            append, connect, end = self._policy(X, A, NX, NX_rep, last_append_mask)\n",
    "            l = self._likelihood(init, append, connect, end, action_0, actions, iw_ids, log_p, batch_size, iw_size)\n",
    "            if self.mode=='likelihood':\n",
    "                return l\n",
    "            else:\n",
    "                return -l.mean()\n",
    "        elif self.mode == 'decode_0':\n",
    "            return self._policy_0(input[0])\n",
    "        elif self.mode == 'decode_step':\n",
    "            X, A, NX, NX_rep, last_append_mask = input\n",
    "            return self._policy(X, A, NX, NX_rep, last_append_mask)\n",
    "\n",
    "\n",
    "class MoleculeGenerator_RNN(MoleculeGenerator):\n",
    "\n",
    "    __metaclass__ = ABCMeta\n",
    "\n",
    "    def __init__(self, N_A, N_B, D, F_e, F_skip, F_c, Fh_policy, activation,\n",
    "                 N_rnn, *args, **kwargs):\n",
    "        super(MoleculeGenerator_RNN, self).__init__(N_A, N_B, D, F_e, F_skip, F_c, Fh_policy, activation,\n",
    "                                                    *args, **kwargs)\n",
    "        self.N_rnn = N_rnn\n",
    "\n",
    "        with self.name_scope():\n",
    "            self.rnn = gluon.rnn.GRU(hidden_size=self.F_c[-1],\n",
    "                                     num_layers=self.N_rnn,\n",
    "                                     layout='NTC', input_size=self.F_c[-1] * 2)\n",
    "\n",
    "    def _rnn_train(self, X, NX, NX_rep, graph_to_rnn, rnn_to_graph, NX_cum):\n",
    "        X_avg = SegmentSumFn(NX_rep, NX.shape[0])(X) / nd.cast(unsqueeze(NX, 1), 'float32')\n",
    "        X_curr = nd.take(X, indices=NX_cum-1)\n",
    "        X = nd.concat(X_avg, X_curr, dim=1)\n",
    "\n",
    "        # rnn\n",
    "        X = nd.take(X, indices=graph_to_rnn) # batch_size, iw_size, length, num_features\n",
    "        batch_size, iw_size, length, num_features = X.shape\n",
    "        X = X.reshape([batch_size*iw_size, length, num_features])\n",
    "        X = self.rnn(X)\n",
    "\n",
    "        X = X.reshape([batch_size, iw_size, length, -1])\n",
    "        X = nd.gather_nd(X, indices=rnn_to_graph)\n",
    "\n",
    "        return X\n",
    "\n",
    "    def _rnn_test(self, X, NX, NX_rep, NX_cum, h):\n",
    "        # note: one partition for one molecule\n",
    "        X_avg = SegmentSumFn(NX_rep, NX.shape[0])(X) / nd.cast(unsqueeze(NX, 1), 'float32')\n",
    "        X_curr = nd.take(X, indices=NX_cum - 1)\n",
    "        X = nd.concat(X_avg, X_curr, dim=1) # size: [NX, F_in * 2]\n",
    "\n",
    "        # rnn\n",
    "        X = unsqueeze(X, axis=1)\n",
    "        X, h = self.rnn(X, h)\n",
    "\n",
    "        X = squeeze(X, axis=1)\n",
    "        return X, h\n",
    "\n",
    "    def _policy(self, X, A, NX, NX_rep, last_append_mask, graph_to_rnn, rnn_to_graph, NX_cum):\n",
    "        # get initial embedding\n",
    "        X = self.embedding_atom(X) + self.embedding_mask(last_append_mask)\n",
    "\n",
    "        # convolution\n",
    "        X = self._graph_conv_forward(X, A)\n",
    "\n",
    "        # linear\n",
    "        X = self.dense(X)\n",
    "\n",
    "        # rnn\n",
    "        X_mol = self._rnn_train(X, NX, NX_rep, graph_to_rnn, rnn_to_graph, NX_cum)\n",
    "\n",
    "        # policy\n",
    "        append, connect, end = self.policy_h(X, NX, NX_rep, X_mol)\n",
    "\n",
    "        return append, connect, end\n",
    "\n",
    "    def _decode_step(self, X, A, NX, NX_rep, last_append_mask, NX_cum, h):\n",
    "        # get initial embedding\n",
    "        X = self.embedding_atom(X) + self.embedding_mask(last_append_mask)\n",
    "\n",
    "        # convolution\n",
    "        X = self._graph_conv_forward(X, A)\n",
    "\n",
    "        # linear\n",
    "        X = self.dense(X)\n",
    "\n",
    "        # rnn\n",
    "        X_mol, h = self._rnn_test(X, NX, NX_rep, NX_cum, h)\n",
    "\n",
    "        # policy\n",
    "        append, connect, end = self.policy_h(X, NX, NX_rep, X_mol)\n",
    "\n",
    "        return append, connect, end, h\n",
    "\n",
    "    def forward(self, *input):\n",
    "        if self.mode=='loss' or self.mode=='likelihood':\n",
    "            X, A, iw_ids, last_append_mask, \\\n",
    "            NX, NX_rep, action_0, actions, log_p, \\\n",
    "            batch_size, iw_size, \\\n",
    "            graph_to_rnn, rnn_to_graph, NX_cum = input\n",
    "\n",
    "            init = self._policy_0(X.context).tile([batch_size * iw_size, 1])\n",
    "            append, connect, end = self._policy(X, A, NX, NX_rep, last_append_mask, graph_to_rnn, rnn_to_graph, NX_cum)\n",
    "            l = self._likelihood(init, append, connect, end, action_0, actions, iw_ids, log_p, batch_size, iw_size)\n",
    "            if self.mode=='likelihood':\n",
    "                return l\n",
    "            else:\n",
    "                return -l.mean()\n",
    "        elif self.mode == 'decode_0':\n",
    "            return self._policy_0(input[0])\n",
    "        elif self.mode == 'decode_step':\n",
    "            X, A, NX, NX_rep, last_append_mask, NX_cum, h = input\n",
    "            return self._decode_step(X, A, NX, NX_rep, last_append_mask, NX_cum, h)\n",
    "        else:\n",
    "            raise ValueError\n",
    "            \n",
    "class _TwoLayerDense(nn.Block):\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(_TwoLayerDense, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.input_size = input_size\n",
    "\n",
    "        with self.name_scope():\n",
    "            # config 1\n",
    "            self.input = nn.Dense(self.hidden_size, use_bias=False, in_units=self.input_size)\n",
    "            self.bn_input = BatchNorm(in_channels=self.hidden_size)\n",
    "            self.output = nn.Dense(self.output_size, use_bias=True, in_units=self.hidden_size)\n",
    "            \n",
    "            # config 2\n",
    "            #self.bn_input = BatchNorm(in_channels=self.input_size)\n",
    "            #self.output = nn.Dense(self.output_size, use_bias=True, in_units=self.input_size)\n",
    "            \n",
    "            # config 3\n",
    "            #self.input1 = nn.Dense(self.hidden_size, use_bias=False, in_units=self.input_size)\n",
    "            #self.bn_input1 = BatchNorm(in_channels=self.hidden_size)\n",
    "            #self.input2 = nn.Dense(self.hidden_size, use_bias=False, in_units=self.hidden_size)\n",
    "            #self.bn_input2 = BatchNorm(in_channels=self.hidden_size)\n",
    "            #self.output = nn.Dense(self.output_size, use_bias=True, in_units=self.hidden_size)\n",
    "\n",
    "    def forward(self, c):\n",
    "        # config 1\n",
    "        return nd.softmax(self.output(nd.relu(self.bn_input(self.input(c)))), axis=-1)\n",
    "        \n",
    "        # config 2\n",
    "        #return nd.softmax(self.output(nd.relu(self.bn_input(c))), axis=-1)\n",
    "    \n",
    "        # config 3\n",
    "        #return nd.softmax(self.output(nd.relu(self.bn_input2(self.input2(nd.relu(self.bn_input1(self.input1(c))))))), axis=-1)\n",
    "\n",
    "\n",
    "class CMoleculeGenerator_RNN(MoleculeGenerator_RNN):\n",
    "    __metaclass__ = ABCMeta\n",
    "\n",
    "    def __init__(self, N_A, N_B, N_C, D,\n",
    "                 F_e, F_skip, F_c, Fh_policy,\n",
    "                 activation, N_rnn,\n",
    "                 *args, **kwargs):\n",
    "        self.N_C = N_C # number of conditional variables\n",
    "        super(CMoleculeGenerator_RNN, self).__init__(N_A, N_B, D,\n",
    "                                                     F_e, F_skip, F_c, Fh_policy,\n",
    "                                                     activation, N_rnn,\n",
    "                                                     *args, **kwargs)\n",
    "        with self.name_scope():\n",
    "            self.dense_policy_0 = _TwoLayerDense(self.N_C, self.N_A * 3, self.N_A)\n",
    "\n",
    "    @abstractmethod\n",
    "    def _graph_conv_forward(self, X, A, c, ids):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def _policy_0(self, c):\n",
    "        return self.dense_policy_0(c) + 0.0 * self.policy_0.data(c.context)\n",
    "\n",
    "    def _policy(self, X, A, NX, NX_rep, last_append_mask,\n",
    "                graph_to_rnn, rnn_to_graph, NX_cum,\n",
    "                c, ids):\n",
    "        # get initial embedding\n",
    "        X = self.embedding_atom(X) + self.embedding_mask(last_append_mask)\n",
    "\n",
    "        # convolution\n",
    "        X = self._graph_conv_forward(X, A, c, ids)\n",
    "\n",
    "        # linear\n",
    "        X = self.dense(X)\n",
    "\n",
    "        # rnn\n",
    "        X_mol = self._rnn_train(X, NX, NX_rep, graph_to_rnn, rnn_to_graph, NX_cum)\n",
    "\n",
    "        # policy\n",
    "        append, connect, end = self.policy_h(X, NX, NX_rep, X_mol)\n",
    "\n",
    "        return append, connect, end\n",
    "\n",
    "    def _decode_step(self, X, A, NX, NX_rep, last_append_mask, NX_cum, h, c, ids):\n",
    "        # get initial embedding\n",
    "        X = self.embedding_atom(X) + self.embedding_mask(last_append_mask)\n",
    "\n",
    "        # convolution\n",
    "        X = self._graph_conv_forward(X, A, c, ids)\n",
    "\n",
    "        # linear\n",
    "        X = self.dense(X)\n",
    "\n",
    "        # rnn\n",
    "        X_mol, h = self._rnn_test(X, NX, NX_rep, NX_cum, h)\n",
    "\n",
    "        # policy\n",
    "        append, connect, end = self.policy_h(X, NX, NX_rep, X_mol)\n",
    "\n",
    "        return append, connect, end, h\n",
    "\n",
    "\n",
    "    def forward(self, *input):\n",
    "        if self.mode=='loss' or self.mode=='likelihood':\n",
    "            X, A, iw_ids, last_append_mask, \\\n",
    "            NX, NX_rep, action_0, actions, log_p, \\\n",
    "            batch_size, iw_size, \\\n",
    "            graph_to_rnn, rnn_to_graph, NX_cum, \\\n",
    "            c, ids = input\n",
    "\n",
    "            init = nd.tile(unsqueeze(self._policy_0(c), axis=1), [1, iw_size, 1])\n",
    "            append, connect, end = self._policy(X, A, NX, NX_rep, last_append_mask,\n",
    "                                                graph_to_rnn, rnn_to_graph, NX_cum,\n",
    "                                                c, ids)\n",
    "            l = self._likelihood(init, append, connect, end,\n",
    "                                 action_0, actions, iw_ids, log_p,\n",
    "                                 batch_size, iw_size)\n",
    "            if self.mode=='likelihood':\n",
    "                return l\n",
    "            else:\n",
    "                return -l.mean()\n",
    "        elif self.mode == 'decode_0':\n",
    "            return self._policy_0(*input)\n",
    "        elif self.mode == 'decode_step':\n",
    "            X, A, NX, NX_rep, last_append_mask, NX_cum, h, c, ids = input\n",
    "            return self._decode_step(X, A, NX, NX_rep, last_append_mask, NX_cum, h, c, ids)\n",
    "        else:\n",
    "            raise ValueError\n",
    "\n",
    "class CVanillaMolGen_RNN(CMoleculeGenerator_RNN):\n",
    "\n",
    "    def __init__(self, N_A, N_B, N_C, D,\n",
    "                 F_e, F_h, F_skip, F_c, Fh_policy,\n",
    "                 activation, N_rnn, rename=False):\n",
    "        self.rename = rename\n",
    "        super(CVanillaMolGen_RNN, self).__init__(N_A, N_B, N_C, D,\n",
    "                                                 F_e, F_skip, F_c, Fh_policy,\n",
    "                                                 activation, N_rnn,\n",
    "                                                 F_h)\n",
    "\n",
    "    def _build_graph_conv(self, F_h):\n",
    "        self.F_h = list(F_h) if isinstance(F_h, tuple) else F_h\n",
    "        self.conv, self.bn = [], []\n",
    "        for i, (f_in, f_out) in enumerate(zip([self.F_e] + self.F_h[:-1], self.F_h)):\n",
    "            conv = GraphConv(f_in, f_out, self.N_B + self.D)\n",
    "            self.conv.append(conv)\n",
    "            self.register_child(conv)\n",
    "\n",
    "            if i != 0:\n",
    "                bn = BatchNorm(in_channels=f_in)\n",
    "                self.register_child(bn)\n",
    "            else:\n",
    "                bn = None\n",
    "            self.bn.append(bn)\n",
    "\n",
    "        self.bn_skip = BatchNorm(in_channels=sum(self.F_h))\n",
    "        self.linear_skip = Linear_BN(sum(self.F_h), self.F_skip)\n",
    "\n",
    "        # projectors for conditional variable (protein embedding)\n",
    "        self.linear_c = []\n",
    "        for i, f_out in enumerate(self.F_h):\n",
    "            if self.rename:\n",
    "                linear_c = nn.Dense(f_out, use_bias=False, in_units=self.N_C, prefix='cond_{}'.format(i))\n",
    "            else:\n",
    "                linear_c = nn.Dense(f_out, use_bias=False, in_units=self.N_C)\n",
    "            self.register_child(linear_c)\n",
    "            self.linear_c.append(linear_c)\n",
    "\n",
    "    def _graph_conv_forward(self, X, A, c, ids):\n",
    "        X_out = [X]\n",
    "        for conv, bn, linear_c in zip(self.conv, self.bn, self.linear_c):\n",
    "            X = X_out[-1]\n",
    "            if bn is not None:\n",
    "                X_out.append(conv(self.activation(bn(X)), A) + linear_c(c)[ids, :])\n",
    "            else:\n",
    "                X_out.append(conv(X, A) + linear_c(c)[ids, :])\n",
    "        X_out = nd.concat(*X_out[1:], dim=1)\n",
    "        return self.activation(self.linear_skip(self.activation(self.bn_skip(X_out))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Early Stopping Implementation\n",
    "class EarlyStopping(object):\n",
    "    \n",
    "    def __init__(self, patience=5, delta=1e-2, less_is_better=True):\n",
    "\n",
    "        self.patience = patience\n",
    "        self.delta = delta\n",
    "        self.less_is_better = less_is_better\n",
    "        self.best = math.inf if less_is_better else -math.inf\n",
    "        self.counter = 0\n",
    "\n",
    "    def update(self, loss):\n",
    "        if self.best is None:\n",
    "            self.best = loss\n",
    "            return\n",
    "\n",
    "        if self.less_is_better:\n",
    "            # Best loss updated.\n",
    "            if loss < self.best - self.delta:\n",
    "                self.best = loss\n",
    "                self.counter = 0\n",
    "            else:\n",
    "                self.counter += 1\n",
    "        else:\n",
    "            # Best loss updated.\n",
    "            if loss > self.best + self.delta:\n",
    "                self.best = loss\n",
    "                self.counter = 0\n",
    "            else:\n",
    "                self.counter += 1\n",
    "\n",
    "    def step(self, loss):\n",
    "        self.update(loss)\n",
    "\n",
    "        # Return True if the counter exceeded patience.\n",
    "        return self.counter >= self.patience\n",
    "\n",
    "    def get_best_score(self):\n",
    "        return self.best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading and preprocessing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "if all([os.path.isfile(os.path.join(ckpt_dir, _n)) for _n in ['log.out', 'ckpt.params', 'trainer.status']]):\n",
    "    is_continuous = True\n",
    "else:\n",
    "    is_continuous = False\n",
    "\n",
    "cond = Delimited()\n",
    "    \n",
    "if train_only:\n",
    "    dataset = Lambda(dataset_train, lambda _x: _x.strip('\\n').strip('\\r'))\n",
    "\n",
    "    # get sampler and loader for training set\n",
    "    sampler_train = BalancedSampler(cost=[len(l.split('\\t')[0]) for l in dataset], batch_size=batch_size)\n",
    "    loader_train = CMolRNNLoader(dataset, batch_sampler=sampler_train, num_workers=num_workers,\n",
    "                                      k=k, p=p, conditional=cond)\n",
    "\n",
    "    loader_test = []\n",
    "\n",
    "else:\n",
    "    if all([os.path.isfile(os.path.join(ckpt_dir, _n)) for _n in ['log.out', 'ckpt.params', 'trainer.status']]):\n",
    "        is_continuous = True\n",
    "    else:\n",
    "        is_continuous = False\n",
    "\n",
    "    db_train = Lambda(dataset_train, lambda _x: _x.strip('\\n').strip('\\r'))\n",
    "    # get sampler and loader for training set\n",
    "    sampler_train = BalancedSampler(cost=[len(l.split('\\t')[0]) for l in db_train], batch_size=batch_size)\n",
    "    loader_train = CMolRNNLoader(db_train, batch_sampler=sampler_train, num_workers=num_workers,\n",
    "                                      k=k, p=p, conditional=cond)\n",
    "    \n",
    "    db_test = Lambda(dataset_test, lambda _x: _x.strip('\\n').strip('\\r'))\n",
    "    # get sampler and loader for test set\n",
    "    sampler_test = BalancedSampler(cost=[len(l.split('\\t')[0]) for l in db_test], batch_size=batch_size_test)\n",
    "    loader_test = CMolRNNLoader(db_test, batch_sampler=sampler_test, num_workers=num_workers,\n",
    "                                      k=k, p=p, conditional=cond)\n",
    "\n",
    "# get iterator\n",
    "it_train, it_test = iter(loader_train), iter(loader_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construcing the model and initializing the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "z2d5DCSM5715"
   },
   "outputs": [],
   "source": [
    "# build model\n",
    "if not is_continuous:\n",
    "    configs = {'N_C': N_C,\n",
    "               'F_e': F_e,\n",
    "               'F_h': F_h,\n",
    "               'F_skip': F_skip,\n",
    "               'F_c': F_c,\n",
    "               'Fh_policy': Fh_policy,\n",
    "               'activation': activation,\n",
    "               'rename': True,\n",
    "               'N_rnn': N_rnn}\n",
    "    with open(os.path.join(ckpt_dir, 'configs.json'), 'w') as f:\n",
    "        json.dump(configs, f)\n",
    "else:\n",
    "    with open(os.path.join(ckpt_dir, 'configs.json')) as f:\n",
    "        configs = json.load(f)\n",
    "\n",
    "model = CVanillaMolGen_RNN(get_mol_spec().num_atom_types, get_mol_spec().num_bond_types, D=2, **configs)\n",
    "\n",
    "ctx = mx.gpu()\n",
    "model.collect_params().initialize(mx.init.Xavier(), force_reinit=True, ctx=ctx)\n",
    "if not is_continuous:\n",
    "    if cond_type == 'kinase':\n",
    "        model.load_parameters(os.path.join(ckpt_dir, 'ckpt.params'), ctx=ctx, allow_missing=True)\n",
    "else:\n",
    "    model.load_parameters(os.path.join(ckpt_dir, 'ckpt.params'), ctx=ctx)\n",
    "\n",
    "# construct optimizer\n",
    "opt = mx.optimizer.Adam(learning_rate=lr, clip_gradient=clip_grad)\n",
    "trainer = gluon.Trainer(model.collect_params(), opt)\n",
    "if is_continuous:\n",
    "    trainer.load_states(os.path.join(ckpt_dir, 'trainer.status'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1wmxxeJc82lx",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if not is_continuous:\n",
    "    t0 = time.time()\n",
    "    global_counter = 0\n",
    "else:\n",
    "    with open(os.path.join(ckpt_dir, 'log.out')) as f:\n",
    "        records = f.readlines()\n",
    "        if records[-1] != 'Training finished\\n':\n",
    "            final_record = records[-1]\n",
    "        else:\n",
    "            final_record = records[-2]\n",
    "    count, t_final = int(final_record.split('\\t')[0]), float(final_record.split('\\t')[1])\n",
    "    t0 = time.time() - t_final * 60\n",
    "    global_counter = count\n",
    "\n",
    "epoch_no = 1\n",
    "break_train_loop = False\n",
    "early_stopping = EarlyStopping(patience=patience, delta=1e-2, less_is_better=True)\n",
    "\n",
    "with open(os.path.join(ckpt_dir, 'log.out'),\n",
    "          mode='w' if not is_continuous else 'a') as f:\n",
    "    if not is_continuous:\n",
    "        f.write('Training started...\\n')\n",
    "        f.write('step\\ttime(m)\\tloss\\tlr\\n')\n",
    "    while True:\n",
    "        global_counter += 1\n",
    "        eval_now = False\n",
    "        try:\n",
    "            inputs = next(it_train)\n",
    "        except StopIteration:\n",
    "            eval_now = True\n",
    "            print('Epoch {} complete.'.format(epoch_no))\n",
    "            f.write('\\nEpoch {} complete.\\n'.format(epoch_no))\n",
    "            epoch_no += 1\n",
    "            it_train = iter(loader_train)\n",
    "            inputs = next(it_train)\n",
    "\n",
    "        # move to gpu\n",
    "        inputs = CMolRNNLoader.from_numpy_to_tensor(inputs)\n",
    "\n",
    "        with autograd.record():\n",
    "            loss = [(model(*inputs)).as_in_context(mx.gpu())]\n",
    "            loss = sum(loss)\n",
    "            loss.backward()\n",
    "\n",
    "        nd.waitall()\n",
    "        gc.collect()\n",
    "\n",
    "        trainer.step(batch_size=1, ignore_stale_grad=True)\n",
    "\n",
    "        if global_counter % decay_step == 0:\n",
    "            trainer.set_learning_rate(trainer.learning_rate * (1.0 - decay))\n",
    "\n",
    "        if global_counter % summary_step == 0:\n",
    "            model.save_parameters(os.path.join(ckpt_dir, 'ckpt.params'))\n",
    "            trainer.save_states(os.path.join(ckpt_dir, 'trainer.status'))\n",
    "            \n",
    "            print('Training loss = ', (sum(loss)).asnumpy().item())\n",
    "            f.write('{}\\t{:.2f}\\t{:.4f}\\t{:.8f}\\n'.format(global_counter, float(time.time() - t0) / 60, (sum(loss)).asnumpy().item(),\n",
    "                                              trainer.learning_rate))\n",
    "            f.flush()\n",
    "\n",
    "            print('{} iterations done!'.format(global_counter))\n",
    "            \n",
    "        if eval_now:\n",
    "            if train_only:\n",
    "                loss = (sum(loss)).asnumpy().item()\n",
    "            else:\n",
    "                del loss, inputs\n",
    "                gc.collect()\n",
    "\n",
    "                loss = []\n",
    "                while True:\n",
    "                    try:\n",
    "                        inputs = next(it_test)\n",
    "                        with autograd.predict_mode():\n",
    "                            # move to gpu\n",
    "                            inputs = CMolRNNLoader.from_numpy_to_tensor(inputs)\n",
    "                            loss.append(sum([(model(*inputs)).as_in_context(mx.gpu())]))\n",
    "                    except StopIteration:\n",
    "                        loss = (sum(loss)/len(loss)).asnumpy().item()\n",
    "                        print('Validation loss = ', loss)\n",
    "                        f.write('\\nValidation loss: {}\\n\\n'.format(loss))\n",
    "                        stop = early_stopping.step(loss)\n",
    "                        if stop:\n",
    "                            best_score = early_stopping.get_best_score()\n",
    "                            print(f'Early stopping! Best validation loss: {best_score}')\n",
    "                            f.write(f'\\n\\nEarly stopping! Best validation loss: {best_score}\\n\\n')\n",
    "                            break_train_loop = True\n",
    "                        if not break_train_loop:\n",
    "                            f.write('\\nstep\\ttime(h)\\tloss\\tlr\\n')\n",
    "                        it_test = iter(loader_test)\n",
    "                        inputs = next(it_test)\n",
    "                        break\n",
    "\n",
    "        if break_train_loop:\n",
    "            break\n",
    "        \n",
    "        if train_only and epoch_no > max_epochs:\n",
    "            break\n",
    "\n",
    "    # save before exit\n",
    "    model.save_parameters(os.path.join(ckpt_dir, 'ckpt.params'))\n",
    "    trainer.save_states(os.path.join(ckpt_dir, 'trainer.status'))\n",
    "\n",
    "    f.write('Training finished\\n')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyN7lEvr9ZvHj02o6K2PAX84",
   "collapsed_sections": [],
   "name": "Multi_Obj_CGGM.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
